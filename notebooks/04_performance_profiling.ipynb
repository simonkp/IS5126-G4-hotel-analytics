{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Performance Profiling\n",
    "\n",
    "**Objective:** Ensure system performs well with production-scale data.\n",
    "\n",
    "**Areas to Profile:**\n",
    "- Query performance (database operations)\n",
    "- Code performance (Python/pandas operations)\n",
    "\n",
    "**Why This Matters:** System must handle 80K+ reviews efficiently for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd() if (Path.cwd() / \"src\").exists() else Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import time\n",
    "import io\n",
    "import sqlite3\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from src.utils import get_db_path\n",
    "from src.data_processing import REVIEWS_INDEXES\n",
    "from src.benchmarking import get_reviews_df, create_comparable_groups, extract_hotel_features\n",
    "\n",
    "db_path = get_db_path(sample=False)\n",
    "NUM_RUNS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Performance: Quantified Improvements (Baseline vs With Indexes)\n",
    "\n",
    "We measure **before** and **after** adding indexes to show quantified improvement (assignment: \"Performance profiling with quantified improvements\").\n",
    "\n",
    "**Steps:** Drop indexes → run queries (baseline) → create indexes → run same queries (with indexes) → report improvement %.  \n",
    "**Note:** This cell sequence modifies the DB in place (drops then recreates indexes). End state: indexes present.\n",
    "\n",
    "**Test queries:** Count, Group by hotel, Filter by rating, Filter by offering_id (dashboard-style lookup), Complex aggregation.  \n",
    "Each query runs 5 times; we report average baseline ms, average with-index ms, and improvement %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample offering_id for the \"Filter by offering_id\" query (dashboard-style lookup)\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "sample_offering_id = conn.execute(\"SELECT offering_id FROM reviews LIMIT 1\").fetchone()[0]\n",
    "conn.close()\n",
    "\n",
    "test_queries = [\n",
    "    (\"Count all reviews\", \"SELECT COUNT(*) FROM reviews\"),\n",
    "    (\"Avg rating by hotel\", \"SELECT offering_id, AVG(rating_overall) FROM reviews GROUP BY offering_id\"),\n",
    "    (\"Filter by rating >= 4\", \"SELECT * FROM reviews WHERE rating_overall >= 4 LIMIT 1000\"),\n",
    "    (\"Filter by offering_id\", f\"SELECT * FROM reviews WHERE offering_id = {sample_offering_id} LIMIT 1000\"),\n",
    "    (\"Complex aggregation\", \"\"\"\n",
    "        SELECT offering_id,\n",
    "               COUNT(*) as n,\n",
    "               AVG(rating_overall) as avg_rating,\n",
    "               AVG(rating_cleanliness) as avg_clean\n",
    "        FROM reviews\n",
    "        WHERE rating_overall >= 3.5\n",
    "        GROUP BY offering_id\n",
    "        HAVING COUNT(*) >= 10\n",
    "        ORDER BY avg_rating DESC\n",
    "        LIMIT 100\n",
    "    \"\"\"),\n",
    "]\n",
    "\n",
    "# Index names to drop (must match REVIEWS_INDEXES in data_processing.py)\n",
    "DROP_INDEXES = [\n",
    "    \"DROP INDEX IF EXISTS idx_reviews_offering;\",\n",
    "    \"DROP INDEX IF EXISTS idx_reviews_author;\",\n",
    "    \"DROP INDEX IF EXISTS idx_reviews_rating_overall;\",\n",
    "    \"DROP INDEX IF EXISTS idx_reviews_offering_rating_clean;\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Baseline (no indexes)\n",
    "\n",
    "Drop indexes, then run each query 5 times and record average/min/max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (no indexes):\n",
      "  Count all reviews: avg=0.40ms\n",
      "  Avg rating by hotel: avg=341.37ms\n",
      "  Filter by rating >= 4: avg=13.31ms\n",
      "  Filter by offering_id: avg=210.45ms\n",
      "  Complex aggregation: avg=294.57ms\n"
     ]
    }
   ],
   "source": [
    "def run_query_timing(conn, test_queries, num_runs):\n",
    "    \"\"\"Run each query num_runs times; return list of {query, avg_time, min_time, max_time}.\"\"\"\n",
    "    results = []\n",
    "    for name, query in test_queries:\n",
    "        times = []\n",
    "        for _ in range(num_runs):\n",
    "            start = time.time()\n",
    "            conn.execute(query).fetchall()\n",
    "            times.append(time.time() - start)\n",
    "        avg_time = sum(times) / len(times)\n",
    "        results.append({\"query\": name, \"avg_time\": avg_time, \"min_time\": min(times), \"max_time\": max(times)})\n",
    "    return results\n",
    "\n",
    "# Drop indexes (baseline = no indexes)\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "for stmt in DROP_INDEXES:\n",
    "    conn.execute(stmt)\n",
    "conn.commit()\n",
    "\n",
    "results_baseline = run_query_timing(conn, test_queries, NUM_RUNS)\n",
    "conn.close()\n",
    "print(\"Baseline (no indexes):\")\n",
    "for r in results_baseline:\n",
    "    print(f\"  {r['query']}: avg={r['avg_time']*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: With indexes\n",
    "\n",
    "Recreate indexes (same as data_processing.REVIEWS_INDEXES), then run same queries 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With indexes:\n",
      "  Count all reviews: avg=0.40ms\n",
      "  Avg rating by hotel: avg=10.71ms\n",
      "  Filter by rating >= 4: avg=15.51ms\n",
      "  Filter by offering_id: avg=0.40ms\n",
      "  Complex aggregation: avg=11.20ms\n"
     ]
    }
   ],
   "source": [
    "# Create indexes (same as data_processing.REVIEWS_INDEXES)\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "for stmt in REVIEWS_INDEXES:\n",
    "    conn.execute(stmt)\n",
    "conn.commit()\n",
    "\n",
    "results_with_index = run_query_timing(conn, test_queries, NUM_RUNS)\n",
    "conn.close()\n",
    "print(\"With indexes:\")\n",
    "for r in results_with_index:\n",
    "    print(f\"  {r['query']}: avg={r['avg_time']*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Query  Baseline (ms)  With indexes (ms)  Improvement (%)\n",
      "    Count all reviews           0.40               0.40             -0.1\n",
      "  Avg rating by hotel         341.37              10.71             96.9\n",
      "Filter by rating >= 4          13.31              15.51            -16.5\n",
      "Filter by offering_id         210.45               0.40             99.8\n",
      "  Complex aggregation         294.57              11.20             96.2\n",
      "\n",
      "Wrote d:\\dev\\study\\IS5126-G4-hotel-analytics\\profiling\\query_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Summary: quantified improvement (baseline vs with indexes)\n",
    "summary_rows = []\n",
    "for b, w in zip(results_baseline, results_with_index):\n",
    "    baseline_ms = b[\"avg_time\"] * 1000\n",
    "    with_index_ms = w[\"avg_time\"] * 1000\n",
    "    improvement = (1 - with_index_ms / baseline_ms) * 100 if baseline_ms > 0 else 0\n",
    "    summary_rows.append({\n",
    "        \"Query\": b[\"query\"],\n",
    "        \"Baseline (ms)\": round(baseline_ms, 2),\n",
    "        \"With indexes (ms)\": round(with_index_ms, 2),\n",
    "        \"Improvement (%)\": round(improvement, 1),\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Write profiling output (baseline + with-index + summary) to file\n",
    "buf = io.StringIO()\n",
    "buf.write(\"QUERY PERFORMANCE: BASELINE (no indexes) vs WITH INDEXES\\n\")\n",
    "buf.write(\"=\" * 80 + \"\\n\\n\")\n",
    "buf.write(\"Baseline (no indexes):\\n\")\n",
    "for r in results_baseline:\n",
    "    buf.write(f\"  {r['query']}: avg={r['avg_time']*1000:.2f}ms, min={r['min_time']*1000:.2f}ms, max={r['max_time']*1000:.2f}ms\\n\")\n",
    "buf.write(\"\\nWith indexes:\\n\")\n",
    "for r in results_with_index:\n",
    "    buf.write(f\"  {r['query']}: avg={r['avg_time']*1000:.2f}ms, min={r['min_time']*1000:.2f}ms, max={r['max_time']*1000:.2f}ms\\n\")\n",
    "buf.write(\"\\nQUANTIFIED IMPROVEMENT:\\n\")\n",
    "buf.write(summary_df.to_string(index=False) + \"\\n\")\n",
    "query_profiling_txt = buf.getvalue()\n",
    "output_path = project_root / \"profiling\" / \"query_results.txt\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "output_path.write_text(query_profiling_txt, encoding=\"utf-8\")\n",
    "print(f\"\\nWrote {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: EXPLAIN QUERY PLAN (with indexes)\n",
    "\n",
    "Execution plans after indexes are in place (justifies index usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUERY EXECUTION PLANS (with indexes)\n",
      "======================================================================\n",
      "\n",
      "Count all reviews:\n",
      "  Query: SELECT COUNT(*) FROM reviews\n",
      "  Plan:\n",
      "    (4, 0, 0, 'SCAN reviews USING COVERING INDEX idx_reviews_rating_overall')\n",
      "\n",
      "Avg rating by hotel:\n",
      "  Query: SELECT offering_id, AVG(rating_overall) FROM reviews GROUP BY offering_id\n",
      "  Plan:\n",
      "    (6, 0, 0, 'SCAN reviews USING COVERING INDEX idx_reviews_offering_rating_clean')\n",
      "\n",
      "Filter by rating >= 4:\n",
      "  Query: SELECT * FROM reviews WHERE rating_overall >= 4 LIMIT 1000\n",
      "  Plan:\n",
      "    (4, 0, 0, 'SEARCH reviews USING INDEX idx_reviews_rating_overall (rating_overall>?)')\n",
      "\n",
      "Filter by offering_id:\n",
      "  Query: SELECT * FROM reviews WHERE offering_id = 72572 LIMIT 1000\n",
      "  Plan:\n",
      "    (4, 0, 0, 'SEARCH reviews USING INDEX idx_reviews_offering_rating_clean (offering_id=?)')\n",
      "\n",
      "Complex aggregation:\n",
      "  Query: \n",
      "        SELECT offering_id,\n",
      "               COUNT(*) as n,\n",
      "               AVG(ra...\n",
      "  Plan:\n",
      "    (8, 0, 0, 'SCAN reviews USING COVERING INDEX idx_reviews_offering_rating_clean')\n",
      "    (56, 0, 0, 'USE TEMP B-TREE FOR ORDER BY')\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"QUERY EXECUTION PLANS (with indexes)\")\n",
    "print(\"=\" * 70)\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "for name, query in test_queries:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Query: {query[:80]}{'...' if len(query) > 80 else ''}\")\n",
    "    print(\"  Plan:\")\n",
    "    for row in conn.execute(f\"EXPLAIN QUERY PLAN {query}\").fetchall():\n",
    "        print(f\"    {row}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Performance Analysis\n",
    "\n",
    "Profiling Python operations to identify bottlenecks in our benchmarking code.\n",
    "\n",
    "**What we're profiling:** The complete benchmarking workflow (feature extraction + clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hotel-level features...\n",
      "Analyzing review text for hotel characteristics...\n",
      "Creating 6 comparable groups...\n",
      "Data shape: (3374, 7)\n",
      "Unique hotels: 3374\n",
      "\n",
      "Testing different cluster counts:\n",
      "  K=3: silhouette=0.297, min_size=459, max_size=1487\n",
      "  K=4: silhouette=0.306, min_size=258, max_size=1341\n",
      "  K=5: silhouette=0.291, min_size=105, max_size=1366\n",
      "  K=6: silhouette=0.303, min_size=69, max_size=892\n",
      "  K=7: silhouette=0.315, min_size=45, max_size=826\n",
      "  K=8: silhouette=0.333, min_size=75, max_size=926\n",
      "  K=9: silhouette=0.333, min_size=15, max_size=776\n",
      "  K=10: silhouette=0.310, min_size=15, max_size=740\n",
      "  K=11: silhouette=0.314, min_size=14, max_size=741\n",
      "  K=12: silhouette=0.281, min_size=14, max_size=588\n",
      "\n",
      " Selected K=9 with silhouette=0.333\n",
      "         3856159 function calls (3779609 primitive calls) in 25.891 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2108 to 30 due to restriction <30>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     30/1    0.003    0.000   25.913   25.913 {built-in method builtins.exec}\n",
      "        1    0.003    0.003   25.890   25.890 517630660.py:2(_run_benchmark_workflow)\n",
      "     3374    0.249    0.000   15.560    0.005 benchmarking.py:98(extract_text_features_for_hotel)\n",
      "        1    0.067    0.067   12.546   12.546 benchmarking.py:26(extract_hotel_features)\n",
      "    30381    0.088    0.000   12.251    0.000 {built-in method builtins.sum}\n",
      "       39    0.019    0.000    7.081    0.182 base_events.py:1910(_run_once)\n",
      "        1    0.001    0.001    5.789    5.789 benchmarking.py:169(create_comparable_groups)\n",
      "       11    0.000    0.000    3.192    0.290 base.py:1319(wrapper)\n",
      "       10    0.000    0.000    3.189    0.319 _kmeans.py:1047(fit_predict)\n",
      "       10    0.004    0.000    3.182    0.318 _kmeans.py:1432(fit)\n",
      "    60/10    0.001    0.000    2.515    0.251 _param_validation.py:187(wrapper)\n",
      "       10    0.000    0.000    2.512    0.251 _unsupervised.py:49(silhouette_score)\n",
      "       10    0.002    0.000    2.511    0.251 _unsupervised.py:203(silhouette_samples)\n",
      "       20    0.056    0.003    2.499    0.125 pairwise.py:2094(pairwise_distances_chunked)\n",
      "    10248    0.088    0.000    2.187    0.000 frame.py:4073(__getitem__)\n",
      "       10    0.000    0.000    2.103    0.210 pairwise.py:2278(pairwise_distances)\n",
      "     7642    1.989    0.000    1.989    0.000 benchmarking.py:143(<genexpr>)\n",
      "    18963    1.953    0.000    1.953    0.000 benchmarking.py:145(<genexpr>)\n",
      "    15955    1.933    0.000    1.933    0.000 benchmarking.py:144(<genexpr>)\n",
      "    13912    1.914    0.000    1.914    0.000 benchmarking.py:141(<genexpr>)\n",
      "    16884    1.851    0.000    1.851    0.000 benchmarking.py:146(<genexpr>)\n",
      "        1    0.000    0.000    1.816    1.816 parallel.py:631(cpu_count)\n",
      "        1    0.000    0.000    1.816    1.816 context.py:78(cpu_count)\n",
      "        1    0.000    0.000    1.816    1.816 context.py:227(_count_physical_cores)\n",
      "        1    0.000    0.000    1.816    1.816 context.py:286(_count_physical_cores_win32)\n",
      "        1    0.000    0.000    1.816    1.816 subprocess.py:506(run)\n",
      "     5499    1.806    0.000    1.806    0.000 benchmarking.py:142(<genexpr>)\n",
      "        1    0.000    0.000    1.802    1.802 subprocess.py:1165(communicate)\n",
      "        1    0.000    0.000    1.786    1.786 subprocess.py:1603(_communicate)\n",
      "    31/30    0.000    0.000    1.786    0.060 threading.py:1153(_wait_for_tstate_lock)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Wrote d:\\dev\\study\\IS5126-G4-hotel-analytics\\profiling\\code_profiling.txt\n"
     ]
    }
   ],
   "source": [
    "# Use runctx() so profiling is self-contained (no enable/disable state; avoids \"another profiler active\")\n",
    "def _run_benchmark_workflow():\n",
    "    df = get_reviews_df(sample=False)\n",
    "    features = extract_hotel_features(df)\n",
    "    features_clustered, sil_score, profiles = create_comparable_groups(features, n_clusters=6)\n",
    "    return None\n",
    "\n",
    "prof = cProfile.Profile()\n",
    "prof.runctx(\"_run_benchmark_workflow()\", globals(), locals())\n",
    "\n",
    "# Generate report\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(prof, stream=s).strip_dirs().sort_stats(\"cumulative\")\n",
    "ps.print_stats(30)\n",
    "\n",
    "code_profiling_txt = s.getvalue()\n",
    "\n",
    "# Write to file\n",
    "output_path = project_root / \"profiling\" / \"code_profiling.txt\"\n",
    "output_path.write_text(code_profiling_txt, encoding=\"utf-8\")\n",
    "\n",
    "# Show in notebook\n",
    "print(code_profiling_txt)\n",
    "print(f\"\\n Wrote {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
